{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 3 - Datos de precipitaciones (NOAA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El sitio Web NOOA del gobierno de EEUU proporciona datasets de datos climáticos a través de esta página Web: \n",
    "http://www.ncdc.noaa.gov/cdo-web/datasets  \n",
    " \n",
    "Entre ellos tenemos los datasets “Quality Controlled Local Climatological Data (QCLCD)” que se describen aquí: http://www.ncdc.noaa.gov/data-access/land-based-station-data/land-baseddatasets/quality-controlled-local-climatological-data-qclcd\n",
    "\n",
    "Entre los datos que se encuentran en los datasets QCLCD están las precipitaciones por años y estaciones. Por ejemplo, podemos descargar los datasets de aquí: \n",
    "http://www.ncdc.noaa.gov/orders/qclcd/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pide tomar datos de varios años (queda a la elección del estudiante) de este conjunto de datasets para las precipitaciones y obtener los siguientes resúmenes: \n",
    "- Día en que ha habido más precipitaciones. \n",
    "- Año en que ha habido más precipitaciones (obteniendo la media de cada año) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1 -  Utilizando DataFrames y los ficheros de texto que se decargan directamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importamos bibliotecas\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** NOTA - Los ficheros comprimidos se han descargado de la página web de forma manual en la misma carpeta donde se encuentra este notebook **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se han descargado los ficheros comprimidos con los datos de seis años (QCLCD2010.zip, QCLCD2011.zip, QCLCD2012.zip, QCLCD2013.zip, QCLCD2014.zip, QCLCD2015.zip). Solo se han extraido los ficheros *AAAAMMdaily.txt*. Para cada año, se han extraido en una carpeta propia, con el mismo nombre que el fichero comprimido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extension = '.zip'\n",
    "for item in os.listdir(os.getcwd()):\n",
    "    if item.endswith(extension):\n",
    "        zip_name = item\n",
    "        zip_ref = zipfile.ZipFile(zip_name)\n",
    "        extractpath = zip_name[:-6]         #Creamos la carpeta para descomprimir cada fichero\n",
    "\n",
    "        for info in zip_ref.infolist():\n",
    "            #Solo extraemos los ficheros AAAMMdaily.txt\n",
    "            if info.filename.endswith('daily.txt'):\n",
    "                zip_ref.extract(info, extractpath)\n",
    "        zip_ref.close()\n",
    "        os.remove(zip_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras este paso, tenemos en el mismo directorio del notebook un subdirectorio por cada año de 2010 a 2015 y dentro de cada subdirectorio contiene doce ficheros .txt, con la información diaria para cada mes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver el tamaño que ocupan todos estos ficheros en disco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El volumen de la unidad C es Windows\n",
      " El n£mero de serie del volumen es: C666-A5DE\n",
      "\n",
      " Directorio de C:\\Users\\Mikko\\Documents\\Estela\\CIFF\\EntornosDS\\Python\\Pruebas\\Prueba2_Estela_Romero\\Parte3\\QCLCD2010\n",
      "\n",
      "06/03/2017  22:57    <DIR>          .\n",
      "06/03/2017  22:57    <DIR>          ..\n",
      "06/03/2017  22:57         4.787.513 201001daily.txt\n",
      "06/03/2017  22:57         4.336.100 201002daily.txt\n",
      "06/03/2017  22:57         4.772.512 201003daily.txt\n",
      "06/03/2017  22:57         4.575.041 201004daily.txt\n",
      "06/03/2017  22:57         4.772.638 201005daily.txt\n",
      "06/03/2017  22:57         4.712.520 201006daily.txt\n",
      "06/03/2017  22:57         4.855.295 201007daily.txt\n",
      "06/03/2017  22:57         4.879.761 201008daily.txt\n",
      "06/03/2017  22:57         4.742.360 201009daily.txt\n",
      "06/03/2017  22:57         4.987.610 201010daily.txt\n",
      "06/03/2017  22:57         4.846.759 201011daily.txt\n",
      "06/03/2017  22:57         5.021.534 201012daily.txt\n",
      "              12 archivos     57.289.643 bytes\n",
      "               2 dirs  742.080.389.120 bytes libres\n",
      " El volumen de la unidad C es Windows\n",
      " El n£mero de serie del volumen es: C666-A5DE\n",
      "\n",
      " Directorio de C:\\Users\\Mikko\\Documents\\Estela\\CIFF\\EntornosDS\\Python\\Pruebas\\Prueba2_Estela_Romero\\Parte3\\QCLCD2011\n",
      "\n",
      "06/03/2017  22:57    <DIR>          .\n",
      "06/03/2017  22:57    <DIR>          ..\n",
      "06/03/2017  22:57         5.043.738 201101daily.txt\n",
      "06/03/2017  22:57         4.547.905 201102daily.txt\n",
      "06/03/2017  22:57         5.026.117 201103daily.txt\n",
      "06/03/2017  22:57         4.862.636 201104daily.txt\n",
      "06/03/2017  22:57         4.997.967 201105daily.txt\n",
      "06/03/2017  22:57         4.828.967 201106daily.txt\n",
      "06/03/2017  22:57         4.985.972 201107daily.txt\n",
      "06/03/2017  22:57         4.977.458 201108daily.txt\n",
      "06/03/2017  22:57         4.830.055 201109daily.txt\n",
      "06/03/2017  22:57         5.327.696 201110daily.txt\n",
      "06/03/2017  22:57         5.172.376 201111daily.txt\n",
      "06/03/2017  22:57         5.348.904 201112daily.txt\n",
      "              12 archivos     59.949.791 bytes\n",
      "               2 dirs  742.079.795.200 bytes libres\n",
      " El volumen de la unidad C es Windows\n",
      " El n£mero de serie del volumen es: C666-A5DE\n",
      "\n",
      " Directorio de C:\\Users\\Mikko\\Documents\\Estela\\CIFF\\EntornosDS\\Python\\Pruebas\\Prueba2_Estela_Romero\\Parte3\\QCLCD2012\n",
      "\n",
      "06/03/2017  22:58    <DIR>          .\n",
      "06/03/2017  22:58    <DIR>          ..\n",
      "06/03/2017  22:57         5.347.724 201201daily.txt\n",
      "06/03/2017  22:58         5.019.542 201202daily.txt\n",
      "06/03/2017  22:58         5.366.616 201203daily.txt\n",
      "06/03/2017  22:58         5.158.859 201204daily.txt\n",
      "06/03/2017  22:58         5.331.229 201205daily.txt\n",
      "06/03/2017  22:58         5.147.014 201206daily.txt\n",
      "06/03/2017  22:58         5.325.670 201207daily.txt\n",
      "06/03/2017  22:58         5.317.394 201208daily.txt\n",
      "06/03/2017  22:58         5.165.508 201209daily.txt\n",
      "06/03/2017  22:58         5.344.742 201210daily.txt\n",
      "06/03/2017  22:58         5.166.300 201211daily.txt\n",
      "06/03/2017  22:58         5.410.822 201212daily.txt\n",
      "              12 archivos     63.101.420 bytes\n",
      "               2 dirs  742.079.795.200 bytes libres\n",
      " El volumen de la unidad C es Windows\n",
      " El n£mero de serie del volumen es: C666-A5DE\n",
      "\n",
      " Directorio de C:\\Users\\Mikko\\Documents\\Estela\\CIFF\\EntornosDS\\Python\\Pruebas\\Prueba2_Estela_Romero\\Parte3\\QCLCD2013\n",
      "\n",
      "06/03/2017  22:58    <DIR>          .\n",
      "06/03/2017  22:58    <DIR>          ..\n",
      "06/03/2017  22:58         5.359.902 201301daily.txt\n",
      "06/03/2017  22:58         4.869.036 201302daily.txt\n",
      "06/03/2017  22:58         5.350.908 201303daily.txt\n",
      "06/03/2017  22:58         5.201.870 201304daily.txt\n",
      "06/03/2017  22:58         5.367.675 201305daily.txt\n",
      "06/03/2017  22:58         5.163.150 201306daily.txt\n",
      "06/03/2017  22:58         5.340.716 201307daily.txt\n",
      "06/03/2017  22:58         5.335.612 201308daily.txt\n",
      "06/03/2017  22:58         5.202.233 201309daily.txt\n",
      "06/03/2017  22:58         5.348.539 201310daily.txt\n",
      "06/03/2017  22:58         5.186.277 201311daily.txt\n",
      "06/03/2017  22:58         5.400.055 201312daily.txt\n",
      "              12 archivos     63.125.973 bytes\n",
      "               2 dirs  742.079.795.200 bytes libres\n",
      " El volumen de la unidad C es Windows\n",
      " El n£mero de serie del volumen es: C666-A5DE\n",
      "\n",
      " Directorio de C:\\Users\\Mikko\\Documents\\Estela\\CIFF\\EntornosDS\\Python\\Pruebas\\Prueba2_Estela_Romero\\Parte3\\QCLCD2014\n",
      "\n",
      "06/03/2017  22:58    <DIR>          .\n",
      "06/03/2017  22:58    <DIR>          ..\n",
      "06/03/2017  22:58         5.298.607 201401daily.txt\n",
      "06/03/2017  22:58         4.888.063 201402daily.txt\n",
      "06/03/2017  22:58         5.384.675 201403daily.txt\n",
      "06/03/2017  22:58         5.127.323 201404daily.txt\n",
      "06/03/2017  22:58         5.390.044 201405daily.txt\n",
      "06/03/2017  22:58         5.179.124 201406daily.txt\n",
      "06/03/2017  22:58         5.159.922 201407daily.txt\n",
      "06/03/2017  22:58         5.186.604 201408daily.txt\n",
      "06/03/2017  22:58         5.014.534 201409daily.txt\n",
      "06/03/2017  22:58         5.204.504 201410daily.txt\n",
      "06/03/2017  22:58         5.065.963 201411daily.txt\n",
      "06/03/2017  22:58         5.259.262 201412daily.txt\n",
      "              12 archivos     62.158.625 bytes\n",
      "               2 dirs  742.079.799.296 bytes libres\n",
      " El volumen de la unidad C es Windows\n",
      " El n£mero de serie del volumen es: C666-A5DE\n",
      "\n",
      " Directorio de C:\\Users\\Mikko\\Documents\\Estela\\CIFF\\EntornosDS\\Python\\Pruebas\\Prueba2_Estela_Romero\\Parte3\\QCLCD2015\n",
      "\n",
      "06/03/2017  22:58    <DIR>          .\n",
      "06/03/2017  22:58    <DIR>          ..\n",
      "06/03/2017  22:58         4.823.001 201501daily.txt\n",
      "06/03/2017  22:58         4.700.361 201502daily.txt\n",
      "06/03/2017  22:58         5.209.088 201503daily.txt\n",
      "06/03/2017  22:58         5.034.922 201504daily.txt\n",
      "06/03/2017  22:58         5.190.185 201505daily.txt\n",
      "06/03/2017  22:58         4.995.277 201506daily.txt\n",
      "06/03/2017  22:58         5.199.740 201507daily.txt\n",
      "06/03/2017  22:58         5.163.023 201508daily.txt\n",
      "06/03/2017  22:58         8.670.906 201509daily.txt\n",
      "06/03/2017  22:58         8.921.526 201510daily.txt\n",
      "06/03/2017  22:58         8.585.764 201511daily.txt\n",
      "06/03/2017  22:58         8.856.790 201512daily.txt\n",
      "              12 archivos     75.350.583 bytes\n",
      "               2 dirs  742.079.799.296 bytes libres\n"
     ]
    }
   ],
   "source": [
    "extension = '.txt'\n",
    "paths = ['QCLCD2010', 'QCLCD2011', 'QCLCD2012', 'QCLCD2013', 'QCLCD2014', 'QCLCD2015']\n",
    "wd = os.getcwd()\n",
    "for folder in paths:\n",
    "    os.chdir(folder)\n",
    "    %ls \n",
    "    os.chdir(wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada fichero ocupa alrededor de 5MB. Tenemos un total de 72 ficheros, por lo que el espacio en disco que ocupan los datos es alrededor de 360MB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es iterar sobre cada subdirectorio, leer cada fichero y cargar los datos que nos interesan para este ejercicio en un único pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2712377\n",
      "   WBAN  YearMonthDay PrecipTotal\n",
      "0  3013      20100101        0.00\n",
      "1  3013      20100102           T\n",
      "2  3013      20100103        0.00\n",
      "3  3013      20100104        0.00\n",
      "4  3013      20100105        0.00\n",
      "          WBAN  YearMonthDay PrecipTotal\n",
      "2712372  96404      20151227        0.00\n",
      "2712373  96404      20151228        0.00\n",
      "2712374  96404      20151229        0.00\n",
      "2712375  96404      20151230        0.02\n",
      "2712376  96404      20151231        0.00\n"
     ]
    }
   ],
   "source": [
    "extension = '.txt'\n",
    "paths = ['QCLCD2010', 'QCLCD2011', 'QCLCD2012', 'QCLCD2013', 'QCLCD2014', 'QCLCD2015']\n",
    "precipitaciones_df = pd.DataFrame()\n",
    "wd = os.getcwd()\n",
    "for folder in paths:\n",
    "    os.chdir(folder)\n",
    "    for item in os.listdir(os.getcwd()):\n",
    "        if item.endswith(extension):\n",
    "            file_name = item\n",
    "            data = pd.read_csv(file_name, sep = ',', usecols = ['WBAN', 'YearMonthDay', 'PrecipTotal'] )\n",
    "            precipitaciones_df = precipitaciones_df.append(data, ignore_index = True)\n",
    "    os.chdir(wd)\n",
    "print len(precipitaciones_df)\n",
    "print precipitaciones_df.head()\n",
    "print precipitaciones_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos los datos en un único dataframe, vamos a transformar los datos para poder realizar los cálculos que se piden en el ejercicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WBAN             int64\n",
       "YearMonthDay     int64\n",
       "PrecipTotal     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precipitaciones_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar vemos que PrecipTotal tiene dtype 'object', cuando debería ser una variable numérica. Podemos ver en la salida del código anterior, que también contiene valores de tipo string. Vamos a transformar los valores de esta columna para que sean de tipo numérico. Para ello, convertiremos a 'NaN' los valores que no son numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   WBAN  YearMonthDay  PrecipTotal\n",
      "0  3013      20100101          0.0\n",
      "1  3013      20100102          NaN\n",
      "2  3013      20100103          0.0\n",
      "3  3013      20100104          0.0\n",
      "4  3013      20100105          0.0\n"
     ]
    }
   ],
   "source": [
    "precipitaciones_df['PrecipTotal'] = pd.to_numeric(precipitaciones_df['PrecipTotal'], errors = 'coerce')\n",
    "print precipitaciones_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También vemos que la columna 'YearMonthDay' es de tipo int64. Vamos a transformarla a fecha y a crear una columna sólo con la información del año para poder realizar mejor los cálculos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   WBAN YearMonthDay  PrecipTotal  Year\n",
      "0  3013   2010-01-01          0.0  2010\n",
      "1  3013   2010-01-02          NaN  2010\n",
      "2  3013   2010-01-03          0.0  2010\n",
      "3  3013   2010-01-04          0.0  2010\n",
      "4  3013   2010-01-05          0.0  2010\n"
     ]
    }
   ],
   "source": [
    "precipitaciones_df['YearMonthDay'] = pd.to_datetime(precipitaciones_df['YearMonthDay'], format='%Y%m%d')\n",
    "precipitaciones_df['Year'] = precipitaciones_df['YearMonthDay'].map(lambda x: x.year)\n",
    "print precipitaciones_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, procedemos a calcular lo que se nos pide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Día más lluvioso entre 2010 y 2015: 17/11/2015\n",
      "Año más lluvioso entre 2010 y 2015: 2015\n"
     ]
    }
   ],
   "source": [
    "precipitaciones_diarias = precipitaciones_df.groupby('YearMonthDay')['PrecipTotal'].sum()\n",
    "print 'Día más lluvioso entre 2010 y 2015:', precipitaciones_diarias.argmax().strftime('%d/%m/%Y')\n",
    "precipitaciones_anuales = precipitaciones_df.groupby('Year')['PrecipTotal'].sum()\n",
    "print 'Año más lluvioso entre 2010 y 2015:', precipitaciones_anuales.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2 - Paso previo en el que se guardan los datos en un fichero HDF5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importamos bibliotecas necesarias para esta versión\n",
    "import numpy as np\n",
    "import tables as tb\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el fichero **'precipitaciones.h5'** como tabla y, dentro de él, creamos seis grupos, para almacenar por separado la información de cada año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tb.open_file('precipitaciones.h5', mode = 'w', title = 'Datos de precipitaciones entre 2010 y 2015') as f:\n",
    "    #Grupo para el anyo 2010\n",
    "    f.create_group(\"/\", \"QCLCD2010\", \"Datos Precipitaciones Anyo 2010\")\n",
    "    \n",
    "    #Grupo para el anyo 2011\n",
    "    f.create_group(\"/\", \"QCLCD2011\", \"Datos Precipitaciones Anyo 2011\")\n",
    "    \n",
    "    #Grupo para el anyo 2012\n",
    "    f.create_group(\"/\", \"QCLCD2012\", \"Datos Precipitaciones Anyo 2012\")\n",
    "    \n",
    "    #Grupo para el anyo 2013\n",
    "    f.create_group(\"/\", \"QCLCD2013\", \"Datos Precipitaciones Anyo 2013\")\n",
    "    \n",
    "    #Grupo para el anyo 2014\n",
    "    f.create_group(\"/\", \"QCLCD2014\", \"Datos Precipitaciones Anyo 2014\")\n",
    "    \n",
    "    #Grupo para el anyo 2015\n",
    "    f.create_group(\"/\", \"QCLCD2015\", \"Datos Precipitaciones Anyo 2015\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de cargar los datos de los ficheros txt en nuestro fichero HDF5, debemos recordar que la columna 'PrecipTotal' no es de tipo numérico y debemos convertir los datos previamente a la carga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creamos una función de conversion ad hoc:\n",
    "def str2f(x):\n",
    "    if x=='M' or x.strip()=='T' or x=='err':\n",
    "       return float(\"nan\")\n",
    "    else:\n",
    "        return float(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore('precipitaciones.h5',mode='w') as store:\n",
    "    extension = '.txt'\n",
    "    paths = ['QCLCD2010', 'QCLCD2011', 'QCLCD2012', 'QCLCD2013', 'QCLCD2014', 'QCLCD2015']\n",
    "    wd = os.getcwd()\n",
    "    lines = 500\n",
    "    for folder in paths:\n",
    "        os.chdir(folder)\n",
    "        for item in os.listdir(os.getcwd()):\n",
    "            if item.endswith(extension):\n",
    "                file_name = item\n",
    "                for chunk in pd.read_csv(file_name, sep=',', usecols = ['WBAN', 'YearMonthDay', 'PrecipTotal'], \\\n",
    "                                         chunksize=lines, converters={'PrecipTotal':str2f}): \n",
    "                    store.append(folder,chunk, data_columns =[\"PrecipTotal\"])\n",
    "            os.remove(file_name)\n",
    "        os.chdir(wd)\n",
    "        os.rmdir(folder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El volumen de la unidad C es Windows\n",
      " El n£mero de serie del volumen es: C666-A5DE\n",
      "\n",
      " Directorio de C:\\Users\\Mikko\\Documents\\Estela\\CIFF\\EntornosDS\\Python\\Pruebas\\Prueba2_Estela_Romero\\Parte3\n",
      "\n",
      "06/03/2017  23:21    <DIR>          .\n",
      "06/03/2017  23:21    <DIR>          ..\n",
      "06/03/2017  12:48    <DIR>          .ipynb_checkpoints\n",
      "04/03/2017  01:31            48.296 Estela_Romero_Prueba2_Parte3_2.ipynb\n",
      "05/03/2017  11:46            27.697 Estela_Romero_Prueba3_Parte3_21.ipynb\n",
      "06/03/2017  23:11        93.180.139 precipitaciones.h5\n",
      "06/03/2017  23:21            23.441 Prueba2_Parte3_Estela_Romero.ipynb\n",
      "               4 archivos     93.279.573 bytes\n",
      "               3 dirs  742.238.371.840 bytes libres\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, el tamaño en disco del fichero que contiene los datos que necesitamos es de unos 93MB, unas cuatro veces menos que el tamaño ocupado por todos los ficheros .txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez guardados los datos, abrimos el fichero HDF5 en modo lectura, extraemos los datos por año y hacemos los cálculos parciales correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dia más lluvioso entre 2010 y 2015: 17/11/2015\n",
      "Año más lluvioso entre 2010 y 2015: 2015\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('precipitaciones.h5',mode='r') as store:\n",
    "    grupos = [\"QCLCD2010\", \"QCLCD2011\", \"QCLCD2012\", \"QCLCD2013\", \"QCLCD2014\", \"QCLCD2015\"]\n",
    "    prep_diaria_max = 0\n",
    "    prep_anuales = []\n",
    "    for g in grupos:\n",
    "        datos = store.select(g)\n",
    "        prep_anual = datos['PrecipTotal'].sum()\n",
    "        prep_diarias = datos.groupby('YearMonthDay')['PrecipTotal'].sum()\n",
    "        if(prep_diarias.max() > prep_diaria_max):\n",
    "            prep_diaria_max = prep_diarias.max()\n",
    "            dia_mayor_precipitacion = prep_diarias.argmax()\n",
    "        prep_anuales.append(prep_anual)\n",
    "        \n",
    "        \n",
    "anyos = [2010, 2011, 2012, 2013, 2014, 2015]\n",
    "total_precip_anual = pd.Series(prep_anuales, anyos)\n",
    "dia_mayor_precipitacion = datetime.datetime.strptime(str(dia_mayor_precipitacion), '%Y%m%d')\n",
    "print 'Dia más lluvioso entre 2010 y 2015:', datetime.datetime.strftime(dia_mayor_precipitacion, '%d/%m/%Y')\n",
    "print 'Año más lluvioso entre 2010 y 2015:', total_precip_anual.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
